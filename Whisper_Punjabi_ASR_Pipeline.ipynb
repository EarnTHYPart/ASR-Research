{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b22f1c",
   "metadata": {},
   "source": [
    "# Whisper ASR Fine-Tuning Pipeline for Punjabi (Indic-ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e11d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ 1. Imports\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import load_dataset, Audio\n",
    "import torch\n",
    "import torchaudio\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44041a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† 2. Environment and GPU Check\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfaa992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ 3. Load Indic-ASR Dataset for Punjabi\n",
    "try:\n",
    "    dataset = load_dataset(\"ai4bharat/indic-asr\", \"pa\", split=\"train[:1%]\")  # use 1% for test run\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    print(\"‚úÖ Dataset loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Failed to load dataset:\", str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß© 4. Load Whisper Model and Processor\n",
    "try:\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "    model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"punjabi\", task=\"transcribe\")\n",
    "    model.config.suppress_tokens = []\n",
    "    print(\"‚úÖ Whisper model and processor loaded\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Failed to load model:\", str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßº 5. Preprocess Dataset\n",
    "def prepare_dataset(batch):\n",
    "    try:\n",
    "        audio = batch[\"audio\"]\n",
    "        inputs = processor(audio[\"array\"], sampling_rate=16000)\n",
    "        batch[\"input_features\"] = inputs.input_features[0]\n",
    "        with processor.as_target_processor():\n",
    "            batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "    except Exception as e:\n",
    "        print(\"Preprocessing error:\", str(e))\n",
    "        batch[\"input_features\"] = []\n",
    "        batch[\"labels\"] = []\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02678d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)\n",
    "    print(\"‚úÖ Preprocessing completed\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Preprocessing failed:\", str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è 6. Training Arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-punjabi-finetuned\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=100,\n",
    "    max_steps=200,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ 7. Data Collator\n",
    "def data_collator(features):\n",
    "    input_features = [{\"input_features\": f[\"input_features\"]} for f in features if f[\"input_features\"]]\n",
    "    label_features = [f[\"labels\"] for f in features if f[\"labels\"]]\n",
    "    batch = processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "    labels_batch = processor.tokenizer.pad({\"input_ids\": label_features}, return_tensors=\"pt\")\n",
    "    labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52188d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìè 8. Metric Calculation (WER)\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    wer_score = metric.compute(predictions=pred_str, references=label_str)\n",
    "    print(f\"WER: {wer_score:.4f}\")\n",
    "    return {\"wer\": wer_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèãÔ∏è‚Äç‚ôÇÔ∏è 9. Trainer Initialization\n",
    "try:\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        args=training_args,\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=dataset,\n",
    "        tokenizer=processor.feature_extractor,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    print(\"‚úÖ Trainer initialized\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Failed to initialize trainer:\", str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6af798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ 10. Fine-Tuning the Model\n",
    "try:\n",
    "    trainer.train()\n",
    "    print(\"‚úÖ Training completed\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Training failed:\", str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ 11. Evaluate Final WER on a Few Samples\n",
    "results = []\n",
    "for example in dataset.select(range(5)):\n",
    "    try:\n",
    "        input_data = processor(example[\"input_features\"], return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(input_data[\"input_features\"])\n",
    "        transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        results.append((transcription, example[\"text\"]))\n",
    "        print(\"Ref:\", example[\"text\"])\n",
    "        print(\"Hyp:\", transcription)\n",
    "        print(\"---\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Inference failed:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, refs = zip(*results)\n",
    "final_wer = metric.compute(predictions=preds, references=refs)\n",
    "print(\"üîç Final WER on samples:\", final_wer)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
